### Summary
This article provided the method that scientists could simulate the randomized experiments using observational data, without really completing double-blind experiments. First, they divided the whole population into several groups. Then they observed, collected, and computed the first round numbers. After that, several effects were discussed and estimates, so the second round numbers were computed by assigning weights. Finally, they claimed that their findings could explain the observation.

### Reflection
This could exploit currently existing data and avoid potential legitimate and moral conflicts. Of course, this could save a lot of money and time. Note that, various understanding from expertise may lead to controversial explanations on the same observation.

### Inspiration
Given that we randomly choose 50% of observational data and conduct the same analysis several times, what if the results show a stronger/weaker relation? Or if we use 1990-2010 data, could we predict the 2010-2020 data? 
The difference is that the randomized experiments set the population of samples first, and collect all qualified data. However, the pseudo-trials come from the observational data. Will it be more convincing if there are more times but less population conduction?
